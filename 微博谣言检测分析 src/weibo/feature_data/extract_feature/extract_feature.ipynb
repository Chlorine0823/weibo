{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "import numpy as np\n",
    "import jieba\n",
    "from Post_deal import feature_extract, Dimension\n",
    "import math\n",
    "import os\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# load label  id_label_dict\n",
    "weibo_label_file = \"/home/lchen/Datasets/weibo/Weibo.txt\"\n",
    "with open(weibo_label_file, \"r\") as f:\n",
    "    s = f.readlines()\n",
    "id_label_dict = {}\n",
    "for line in s:\n",
    "    ID_label = [item.split(':')[1] for item in line.split('\\t')[:2]]\n",
    "    id_label_dict[ID_label[0]] = int(ID_label[1])\n",
    "\n",
    "# load LDA model\n",
    "with open(\"LDA_model.pkl\",\"rb\") as f:\n",
    "    lda = pickle.load(f)\n",
    "\n",
    "# extract feature\n",
    "path = \"/home/lchen/Datasets/weibo/Weibo\"\n",
    "filenames = [os.path.join(path, filename) for filename in os.listdir(path)]\n",
    "Feature = []\n",
    "label = []\n",
    "for filename in tqdm(filenames):\n",
    "    with open(filename, \"r\") as f:\n",
    "        source = json.load(f)[0]\n",
    "    feature = feature_extract(source)[0].tolist()\n",
    "    source_text = source['text']    \n",
    "    doc = list(jieba.cut(source_text))\n",
    "    doc_bow = lda.id2word.doc2bow(doc)\n",
    "    doc_lda = [0 for i in range(18)]\n",
    "    topic_distribute = lda[doc_bow]\n",
    "    for topic in topic_distribute:\n",
    "        doc_lda[topic[0]] = topic[1]\n",
    "    #Feature.append(feature+doc_lda)\n",
    "    Feature.append(feature)\n",
    "    label.append(id_label_dict[source[\"id\"]])\n",
    "\n",
    "Feature = np.asarray(Feature)\n",
    "label = np.asarray(label)\n",
    "print(\"Feature shape:\", Feature.shape)\n",
    "print(\"label shape:\", label.shape)\n",
    "np.save(\"Feature_Diffuse.npy\", Feature)\n",
    "np.save(\"label_Diffuse.npy\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2351 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- load labels ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.675 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "100%|██████████| 2351/2351 [01:08<00:00, 34.27it/s]\n",
      "100%|██████████| 2313/2313 [01:20<00:00, 28.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import codecs\n",
    "import numpy as np\n",
    "import jieba\n",
    "from Post_deal import feature_extract, Dimension\n",
    "import math\n",
    "import os\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_label(label_path):  # nonrumor-0 rumor-1\n",
    "    print(\"---------- load labels ----------\")\n",
    "    with open(label_path, \"r\") as f:\n",
    "        s = f.readlines()\n",
    "    id_list = [[], []]\n",
    "    for line in s:\n",
    "        ID_label = [item.split(':')[1] for item in line.split('\\t')[:2]]\n",
    "        if ID_label[1] == '0':\n",
    "            id_list[0].append(ID_label[0])\n",
    "        if ID_label[1] == '1':\n",
    "            id_list[1].append(ID_label[0])\n",
    "    return id_list\n",
    "\n",
    "label_path = \"/home/lchen/Datasets/weibo/Weibo.txt\"\n",
    "path = \"/home/lchen/Datasets/weibo/Weibo\"\n",
    "id_list = load_label(label_path)\n",
    "filenames_n = [os.path.join(path, \"%s.json\"% ID) for ID in id_list[0]]\n",
    "filenames_r = [os.path.join(path, \"%s.json\"% ID) for ID in id_list[1]]\n",
    "\n",
    "# load LDA model\n",
    "with open(\"LDA_model.pkl\",\"rb\") as f:\n",
    "    lda = pickle.load(f)\n",
    "\n",
    "# extract feature\n",
    "def extract_feature(filenames):\n",
    "    Feature = []\n",
    "    for filename in tqdm(filenames):\n",
    "        with open(filename, \"r\") as f:\n",
    "            source = json.load(f)[0]\n",
    "        feature = feature_extract(source)[0].tolist()\n",
    "        source_text = source['text']    \n",
    "        doc = list(jieba.cut(source_text))\n",
    "        doc_bow = lda.id2word.doc2bow(doc)\n",
    "        doc_lda = [0 for i in range(18)]\n",
    "        topic_distribute = lda[doc_bow]\n",
    "        for topic in topic_distribute:\n",
    "            doc_lda[topic[0]] = topic[1]\n",
    "        Feature.append(feature+doc_lda)\n",
    "    return np.asarray(Feature)\n",
    "\n",
    "Feature_n = extract_feature(filenames_n)\n",
    "Feature_r = extract_feature(filenames_r)\n",
    "#print(Feature_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "(2313, 46)\n"
     ]
    }
   ],
   "source": [
    "Function_origin = ['URL(post[\\'text\\'])','First_person(post[\\'text\\'])',\n",
    "                   'Pos_micro(post_sentiment)','Neg_micro(post_sentiment)']\n",
    "# Extract features from preprocessed text\n",
    "Function = ['Len(post[\\'text\\'])',# Content-based features\n",
    "            'Positive_words(post[\\'text\\'])','Negative_words(post[\\'text\\'])',\n",
    "            'Sentiment_score(post[\\'text\\'],emoticons)',\n",
    "            'Smiling(emoticons) ','Frowning(emoticons)',\n",
    "            'Hashtags(post[\\'text\\'])','AT(post[\\'text\\'])',\n",
    "            'Q_mark(post[\\'text\\'])','E_mark(post[\\'text\\'])',\n",
    "            'Multi_QE_mark(post[\\'text\\'])',\n",
    "            'Person_description(post)', # User-based features\n",
    "            'Profile(post)','Verified(post)',\n",
    "            'Verified_type(post)','Friends(post)',\n",
    "            'Male(post)','City(post)',\n",
    "            'Follower(post)','Post_count(post)',\n",
    "            'Exect_days(post)','Reputation_score(post)',\n",
    "            'Re_post (post)', # Diffusion-based features\n",
    "            'Comment_count(post)'\n",
    "            ]\n",
    "Functions = Function_origin+Function\n",
    "print(len(Functions))\n",
    "print(Feature_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lchen/anaconda3/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_data(array, num):\n",
    "    avg = np.mean(array)\n",
    "    std = np.mean(array)\n",
    "    return np.random.normal(avg, std*std, num)\n",
    "\n",
    "font = matplotlib.font_manager.FontProperties(fname=\"/home/lchen/Documents/Font/Times_New_Roman.ttf\")\n",
    "\n",
    "def box_plot(i, F1, F2):\n",
    "    #x2 = generate_data(F2[:,i], F1.shape[0])\n",
    "    #x1 = generate_data(F1[:,i], F1.shape[0])\n",
    "    x1 = F1[:, i][:F2.shape[0]]\n",
    "    x2 = F2[:, i]\n",
    "    x1 = np.log(x1)\n",
    "    x2 = np.log(x2)\n",
    "    data = np.vstack((x1, x2))\n",
    "    #print(data.shape)\n",
    "    df = pd.DataFrame(data.T, columns=[\"非谣言\",\"谣言\"])    \n",
    "    plt.figure(figsize =(6,5))\n",
    "    f = df.boxplot(sym = 'o',\n",
    "               vert = True, \n",
    "               whis = 1.5, \n",
    "               patch_artist = True, \n",
    "               meanline = False, \n",
    "               showmeans = True, \n",
    "               showbox = True, showcaps = True, showfliers = True, notch = False, return_type = \"dict\", widths=0.4\n",
    "              )\n",
    "    for box in f['boxes']:\n",
    "        box.set( color='y', linewidth=0.5)        # 箱体边框颜色\n",
    "        box.set( facecolor = 'orange' ,alpha=0.7)    # 箱体内部填充颜色\n",
    "    for whisker in f['whiskers']:\n",
    "        whisker.set(color='k', linewidth=0.5,linestyle='-')\n",
    "    for cap in f['caps']:\n",
    "        cap.set(color='gray', linewidth=2)\n",
    "    for median in f['medians']:\n",
    "        median.set(color='DarkBlue', linewidth=2)\n",
    "    for flier in f['fliers']:\n",
    "        flier.set(marker='o', color='y', alpha=0.5)\n",
    "    plt.xticks(fontproperties=font,fontsize=14,color=\"black\")\n",
    "    # plt.title(Functions[i])\n",
    "    plt.savefig(\"./img/log %d %s.png\" % (i+1, Functions[i]))\n",
    "    plt.show()\n",
    "\n",
    "for i in range(0, 1):\n",
    "    box_plot(i, Feature_n, Feature_r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
